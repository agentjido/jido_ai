defmodule Jido.AI.Actions.OpenaiExCompatibilityTest do
  @moduledoc """
  Comprehensive compatibility tests for the OpenaiEx public API.

  These tests ensure that the public API remains unchanged during the
  migration from provider-specific implementations to ReqLLM.

  This test suite validates:
  - Module existence and public function signatures
  - Parameter validation and error handling
  - Response format compatibility
  - Backward compatibility with existing code
  """
  use ExUnit.Case, async: false
  use Mimic

  alias Jido.AI.Actions.OpenaiEx
  alias Jido.AI.Actions.OpenaiEx.Embeddings
  alias Jido.AI.Actions.OpenaiEx.ImageGeneration
  alias Jido.AI.Actions.OpenaiEx.ToolHelper

  @moduletag :compatibility
  @moduletag :public_api

  setup :set_mimic_global
  setup :verify_on_exit!

  setup do
    # Copy ReqLLM module for mocking
    copy(ReqLLM)
    :ok
  end

  describe "Module existence and structure" do
    test "OpenaiEx module exists and is a Jido Action" do
      assert Code.ensure_loaded?(OpenaiEx)
      assert function_exported?(OpenaiEx, :run, 2)
    end

    test "Embeddings submodule exists" do
      assert Code.ensure_loaded?(Embeddings)
      assert function_exported?(Embeddings, :run, 2)
    end

    test "ImageGeneration submodule exists" do
      assert Code.ensure_loaded?(ImageGeneration)
      # Verify the module exists even if implementation changes
      assert Code.ensure_loaded?(ImageGeneration)
    end

    test "ToolHelper submodule exists with required functions" do
      assert Code.ensure_loaded?(ToolHelper)
      assert function_exported?(ToolHelper, :to_openai_tools, 1)
      assert function_exported?(ToolHelper, :process_response, 2)
    end
  end

  describe "OpenaiEx.run/2 - Public API compatibility" do
    setup do
      # Mock ReqLLM to avoid actual API calls
      stub(ReqLLM, :generate_text, fn _model_id, _messages, _opts ->
        {:ok,
         %{
           content: "Test response",
           role: "assistant",
           finish_reason: "stop",
           usage: %{prompt_tokens: 10, completion_tokens: 5, total_tokens: 15}
         }}
      end)

      :ok
    end

    test "accepts valid model as map" do
      params = %{
        model: %{provider: :openai, model: "gpt-4"},
        messages: [%{role: :user, content: "Hello"}]
      }

      result = OpenaiEx.run(params, %{})
      assert match?({:ok, _}, result) or match?({:error, _}, result)
    end

    test "accepts valid model as tuple" do
      params = %{
        model: {:openai, [model: "gpt-4"]},
        messages: [%{role: :user, content: "Hello"}]
      }

      result = OpenaiEx.run(params, %{})
      assert match?({:ok, _}, result) or match?({:error, _}, result)
    end

    test "accepts messages parameter" do
      params = %{
        model: {:openai, [model: "gpt-4"]},
        messages: [
          %{role: :system, content: "You are helpful"},
          %{role: :user, content: "Hello"}
        ]
      }

      result = OpenaiEx.run(params, %{})
      assert match?({:ok, _}, result) or match?({:error, _}, result)
    end

    test "accepts prompt parameter instead of messages" do
      params = %{
        model: {:openai, [model: "gpt-4"]},
        prompt: "Tell me a joke"
      }

      result = OpenaiEx.run(params, %{})
      assert match?({:ok, _}, result) or match?({:error, _}, result)
    end

    test "validates required parameters - returns error without model" do
      params = %{messages: [%{role: :user, content: "Hello"}]}

      result = OpenaiEx.run(params, %{})

      # Should return an error, not crash
      assert match?({:error, _}, result)
    end

    test "validates required parameters - returns error without messages or prompt" do
      params = %{model: {:openai, [model: "gpt-4"]}}

      result = OpenaiEx.run(params, %{})

      # Should return an error, not crash
      assert match?({:error, _}, result)
    end

    test "accepts optional temperature parameter" do
      params = %{
        model: {:openai, [model: "gpt-4"]},
        messages: [%{role: :user, content: "Hello"}],
        temperature: 0.5
      }

      result = OpenaiEx.run(params, %{})
      assert match?({:ok, _}, result) or match?({:error, _}, result)
    end

    test "accepts optional max_tokens parameter" do
      params = %{
        model: {:openai, [model: "gpt-4"]},
        messages: [%{role: :user, content: "Hello"}],
        max_tokens: 100
      }

      result = OpenaiEx.run(params, %{})
      assert match?({:ok, _}, result) or match?({:error, _}, result)
    end

    test "accepts optional tools parameter" do
      params = %{
        model: {:openai, [model: "gpt-4"]},
        messages: [%{role: :user, content: "Hello"}],
        tools: []
      }

      result = OpenaiEx.run(params, %{})
      assert match?({:ok, _}, result) or match?({:error, _}, result)
    end

    test "accepts streaming parameter" do
      stub(ReqLLM, :stream_text, fn _model_id, _messages, _opts ->
        {:ok, Stream.map([1, 2, 3], fn x -> %{content: "chunk#{x}"} end)}
      end)

      params = %{
        model: {:openai, [model: "gpt-4"]},
        messages: [%{role: :user, content: "Hello"}],
        stream: true
      }

      result = OpenaiEx.run(params, %{})
      assert match?({:ok, _}, result) or match?({:error, _}, result)
    end

    test "returns consistent error format" do
      params = %{
        model: {:invalid_provider, [model: "test"]},
        messages: [%{role: :user, content: "Hello"}]
      }

      result = OpenaiEx.run(params, %{})

      assert {:error, error} = result
      assert is_map(error)
    end
  end

  describe "Embeddings.run/2 - Public API compatibility" do
    test "module exists and has run/2 function" do
      assert function_exported?(Embeddings, :run, 2)
    end

    # Note: Detailed embeddings tests are in dedicated embeddings test suite
    # This just verifies the public API exists
  end

  describe "ToolHelper - Public API compatibility" do
    test "to_openai_tools/1 exists and handles empty list" do
      assert function_exported?(ToolHelper, :to_openai_tools, 1)

      result = ToolHelper.to_openai_tools([])
      assert match?({:ok, _}, result) or match?({:error, _}, result)
    end

    test "process_response/2 exists and handles basic response" do
      assert function_exported?(ToolHelper, :process_response, 2)

      response = %{
        choices: [
          %{
            message: %{
              content: "test",
              role: "assistant",
              tool_calls: []
            }
          }
        ]
      }

      result = ToolHelper.process_response(response, [])
      assert match?({:ok, _}, result) or match?({:error, _}, result)
    end

    test "process_response/2 handles response with tool calls" do
      response = %{
        choices: [
          %{
            message: %{
              content: nil,
              role: "assistant",
              tool_calls: [
                %{
                  id: "call_1",
                  type: "function",
                  function: %{
                    name: "test_function",
                    arguments: "{}"
                  }
                }
              ]
            }
          }
        ]
      }

      result = ToolHelper.process_response(response, [])
      assert match?({:ok, _}, result) or match?({:error, _}, result)
    end
  end

  describe "Response format compatibility" do
    setup do
      stub(ReqLLM, :generate_text, fn _model_id, _messages, _opts ->
        {:ok,
         %{
           content: "Test response",
           role: "assistant",
           finish_reason: "stop",
           usage: %{prompt_tokens: 10, completion_tokens: 5, total_tokens: 15}
         }}
      end)

      :ok
    end

    test "successful response includes expected fields" do
      params = %{
        model: {:openai, [model: "gpt-4"]},
        messages: [%{role: :user, content: "Hello"}]
      }

      case OpenaiEx.run(params, %{}) do
        {:ok, response} ->
          # Response should be a map with content
          assert is_map(response)
          assert Map.has_key?(response, :content) or Map.has_key?(response, "content")

        {:error, _reason} ->
          # Error responses are acceptable in test environment
          :ok
      end
    end

    test "error response has consistent structure" do
      params = %{
        model: {:invalid, [model: "test"]},
        messages: [%{role: :user, content: "Hello"}]
      }

      case OpenaiEx.run(params, %{}) do
        {:error, error} ->
          # Error should be a map or atom/string
          assert is_map(error) or is_atom(error) or is_binary(error)

        {:ok, _} ->
          # Unexpected success
          :ok
      end
    end
  end

  describe "Provider compatibility" do
    setup do
      stub(ReqLLM, :generate_text, fn _model_id, _messages, _opts ->
        {:ok,
         %{
           content: "Test response",
           role: "assistant",
           finish_reason: "stop"
         }}
      end)

      :ok
    end

    test "supports OpenAI provider" do
      params = %{
        model: {:openai, [model: "gpt-4"]},
        messages: [%{role: :user, content: "Hello"}]
      }

      result = OpenaiEx.run(params, %{})
      assert match?({:ok, _}, result) or match?({:error, _}, result)
    end

    test "supports OpenRouter provider" do
      params = %{
        model: {:openrouter, [model: "openai/gpt-4"]},
        messages: [%{role: :user, content: "Hello"}]
      }

      result = OpenaiEx.run(params, %{})
      assert match?({:ok, _}, result) or match?({:error, _}, result)
    end

    test "supports Google provider" do
      params = %{
        model: {:google, [model: "gemini-pro"]},
        messages: [%{role: :user, content: "Hello"}]
      }

      result = OpenaiEx.run(params, %{})
      assert match?({:ok, _}, result) or match?({:error, _}, result)
    end

    test "rejects unsupported providers with clear error" do
      params = %{
        model: {:unsupported_provider, [model: "test"]},
        messages: [%{role: :user, content: "Hello"}]
      }

      result = OpenaiEx.run(params, %{})

      assert {:error, error} = result
      # Error should mention the invalid provider
      assert is_map(error)
    end
  end
end
