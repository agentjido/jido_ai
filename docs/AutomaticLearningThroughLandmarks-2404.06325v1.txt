Automatically Learning HTN Methods from Landmarks
Ruoxi Li1 , Dana Nau1 , Mark Roberts2 , Morgan Fine-Morris2

arXiv:2404.06325v1 [cs.AI] 9 Apr 2024

1

Dept. of Computer Science and Institute for Systems Research, Univ. of Maryland, College Park, MD, USA
2
Navy Center for Applied Research in AI, Naval Research Laboratory, Washington, DC, USA
rli12314@cs.umd.edu, nau@umd.edu, mark.roberts@nrl.navy.mil, morgan.fine-morris.ctr@nrl.navy.mil

Abstract
Hierarchical Task Network (HTN) planning usually requires
a domain engineer to provide manual input about how to decompose a planning problem. Even HTN-M AKER, a wellknown method-learning algorithm, requires a domain engineer to annotate the tasks with information about what to
learn. We introduce C URRICU LAMA, an HTN method
learning algorithm that completely automates the learning
process. It uses landmark analysis to compose annotated
tasks and leverages curriculum learning to order the learning
of methods from simpler to more complex. This eliminates
the need for manual input, resolving a core issue with HTNM AKER. We prove C URRICU LAMA’s soundness, and show
experimentally that it has a substantially similar convergence
rate in learning a complete set of methods to HTN-M AKER.

1

Introduction

ing gradually more complex methods that incorporate previously learned methods.
Landmarks (Hoffmann, Porteous, and Sebastia 2004) are
facts that must appear in every solution to a planning problem. In the context of learning hierarchical knowledge,
methods that achieve landmarks provide a backbone for
solving a planning problem. More critically, landmarks also
provide a natural way to structure methods automatically.
We develop an approach that builds curricula to learn
methods that achieve landmarks. This paper makes the following contributions:
• We introduce C URRICU LAMA, which uses landmarks to
generate curricula for constructing HTN methods. This
approach obviates HTN-M AKER’s need for manual annotation of tasks.
• We prove that the methods learned by C URRICU LAMA
can be used by a hierarchical planner to solve an HTN
planning problem that is equivalent to the classical planning problem from which the methods were learned.

Automated planning systems require a domain expert to provide knowledge about the dynamics of the planning domain.
In Hierarchical Task Networks (HTNs), expert-provided
knowledge includes structural properties and potential hierarchical problem-solving strategies in the form of HTN
decomposition methods. Writing these methods is a significant knowledge engineering burden. Some techniques
(Hogg, Muñoz-Avila, and Kuter 2016; Hogg, Muñoz Avila,
and Kuter 2008) partially overcome this burden by learning
HTN methods after analyzing the semantics of a solution
plan for planning problems. But these techniques still require input from the human designer. We overcome the need
for human input by combining two insights to produce an
algorithm, C URRICU LAMA, that leverages planning landmarks and curriculum learning. Unlike other HTN learning algorithms, C URRICU LAMA doesn’t require a human
to construct a curriculum because it constructs its own curriculum by analyzing the landmarks in planning problems.
Curriculum learning (Bengio et al. 2009) is a training
strategy that improves learning performance by presenting
training examples in increasing order of difficulty. We apply
curriculum learning to the problem of learning HTN methods by emphasizing learning simpler methods before learn-

HTN-M AKER. Our work builds on the HTN method
learning mechanism of the HTN-M AKER algorithm, which
learns hierarchical planning knowledge in the form of decomposition methods for HTNs. HTN-M AKER takes as input the initial states from a set of classical planning problems in a planning domain and solutions to those problems,
as well as a set of semantically-annotated tasks to be accomplished. The algorithm analyzes this semantic information in order to determine which portions of the input plans
accomplish a particular annotated task and constructs HTN
methods based on those analyses. Formally, each annotated
task has a head, preconditions, and goals. For example, here
is the Make-Clear annotated task for the Blocks World domain:

Copyright © 2024 by the authors.
This open access article is published under the Creative Commons
Attribution-NonCommercial 4.0 International License.

1
2
3
4

• Our experimental results show that C URRICU LAMA has
a similar convergence rate to HTN-M AKER in learning a
complete set of methods to solve all the test problems.

2

Background

(:task
:head Make-Clear(?a - block)
:preconditions ()
:goals ((clear ?a)))

What we call goals HTN-M AKER calls effects. It does not
cause the goals to be true; instead, the goals specify what is
needed to be true after performing the annotated task.
Landmarks. Landmarks are a natural way to subdivide a
planning solution. A landmark (Hoffmann, Porteous, and
Sebastia 2004) for a planning problem is a fact that is true
at some point in every plan that solves the problem. A landmark graph is a directed graph where the nodes are landmarks and the edges are orderings. There are four types
of orderings among landmarks: natural, necessary, greedynecessary, and reasonable (see Appendix A for formal definitions.).

3

Learning HTN methods with Curricula
Generated from Landmarks

Suppose we want to teach an HTN learner to learn methods for solving some task τ . An ideal curriculum would focus the learner on the simplest subtasks of τ first, then build
more and more complex subtasks until all of τ is learned.
Learning HTN methods from plan traces is a common approach, and it follows that traces for subtasks of τ will also
be subtraces of a plan trace for τ . Specifically, if π is a plan
trace for solving τ , then the plan trace for solving each subtask τ is a subtrace π[b, e] of π, where [b, e] indicates the
beginning and ending indices of the subtrace. Thus we can
represent a k-step curriculum that learns subtraces as a sequence of triples of the form (bi , ei , τi ) where i ∈ Nk .
Definition 1. A classical planning problem P is a triple
(Σ, s0 , g), where Σ is the classical planning domain description, s0 is the initial state and g is the goal (Ghallab, Nau,
and Traverso 2016).
Definition 2. Given a plan trace π, a curriculum C is a sequence of k curriculum steps of the form (bi , ei , τi ), where
bi and ei specify the starting and ending indices of the subtrace to analyze, and τi specifies the annotated task to learn
from the subtrace for step i ∈ Nk .
For example, consider a Blocks World classical planning
problem with 4 blocks A, B C and D stacked on each other
(see Figure 1) and the goal is to have block A’s top clear.
Formally: initial state s0 ={(on-table A), (on B A), (on C B),
(on D C), (clear D), (hand-empty)}; and goal g={(clear A)}.
A possible solution πclearA is to remove the blocks above
A one by one through 5 actions, which are prefixed with the
character ‘!’ to distinguish them from predicates. Here is a
3-step curriculum for learning methods of πclearA :
Step
a
b
c

Begin
1
1
1

End
1
3
5

Annotated Task
Make-Clear
Make-Clear
Make-Clear

We want step a to learn a method m1 for annotated tasks
Make-Clear from the first action in plan P , this method

tries to clear a block under one block. Then we want step
b to learn a method m2 for annotated tasks Make-Clear
from the first to the third action in plan P , this method tries
to clear a block under two blocks, and would presumably

D
C
B

Action 1: (!Unstack D C)
Action 2: (!Putdown D)
Action 3: (!Unstack C B)
Action 4: (!Putdown C)
Action 5: (!Unstack B A)

A

Figure 1: A Blocks World problem in which the initial state
is a stack of 4 blocks. The goal is to make the bottom block
A clear. The plan to achieve the goal is shown on the right.
Algorithm 1 C URRICU G EN: Curriculum Generation from
Landmarks
Input: a classical planning problem P , a possibly empty set
of HTN methods M
Output: an updated set of HTN methods M
1: (Σ, s0 , g) ← P
2: (V, EV ) ← extract landmark graph from (Σ, s0 , g)
3: add reasonable orders to (V, EV )
4: C ← ⟨⟩ {initialize the curriculum steps}
5: π ← ⟨⟩ {initialize the plan trace}
6: s ← s0 {initialize the current state}
7: i ← 0 {initialize the plan length}
8: while V ̸= ∅ do
9:
select and remove a vertex v in (V, EV ) that has no
predecessors
10:
π ′ ← C LASSICAL P LANNER(Σ, s, v)
11:
s ← γ(s, π)
12:
i ← i + length(π ′ )
13:
concatenate π ′ to π
14:
t ← M AKE A NNOTATED TASK(v)
15:
for k from i to 1 do
16:
append (k, i, t) to C
17: M = C URRICU L EARN(Σ, s0 , π, C, M )
18: return M

contain a subtask Make-Clear that is related to m1 previously learned from the first action. Then step c learns a new
method m3 for Make-Clear that subsumes m2.
C URRICU LAMA, has two subroutines: C URRICU G EN
generates curricula from landmarks while C URRICU L EARN
learns HTN methods from the curricula.

3.1

C URRICU G EN

Since a landmark must be true at some point in every solution to a planning problem, we hypothesized that it would
be useful to learn methods that reach landmarks. Our algorithm, C URRICU G EN (Algorithm 1) extracts landmarks
from a planning problem, then generates a curriculum from
those landmarks.
C URRICU G EN takes as input a classical planning problem. It first generates a landmark graph for P using hm
Landmarks (Line 2) from the landmark generation method
introduced by Keyder, Richter, and Helmert (2010); then it
adds reasonable orders to the landmark graph (Line 3) from
the method described by Hoffmann, Porteous, and Sebas-

Make-Clear) and curriculum steps in which the final in-

dices correspond to the action that achieves the landmark,
and the beginning indices go back to the plan trace’s start:
Step
a
b
c
d
e
f
g
h
i

Figure 2: A landmark graph for clearing block A from
blocks B, C and D above in the Blocks World domain. The
circled nodes are landmarks, where the dashed nodes are the
landmarks that are satisfied in the initial state, and the filled
node is the goal. The edges are orderings among the landmarks, where ‘gn’ stands for greedy necessary ordering, and
‘n’ stands for natural ordering.

Figure 3: The subplans generated from the landmarks.
tia (2004);1 and then it iterates through the landmarks by
their orderings. For each landmark, C URRICU G EN iteratively obtains a solution trace from the current state using a
classical planner and updates the current state by applying
the solution plan (Lines 10 and 11). M AKE A NNOTATED TASK (Line 14) takes as input the current landmark and produces an annotated task that has a task name, empty preconditions, and the landmark as its goals. Given the annotated
task produced from the landmark, C URRICU G EN generates
curriculum steps (Lines 15 and 16) that progressively trace
backward to the beginning of the plan to learn methods.
Example. In the Blocks World problem in Figure 1, the initial state has 4 stacked blocks A, B, C, and D, and the goal is
to clear block A. Excluding the initial state, Figure 2 shows
the landmark graph from C URRICU G EN for (s0 , g), which
consists of 3 landmarks: (clear C) ≺ (clear B) ≺ (clear A).
C URRICU G EN generates subplans to achieve the first,
second and the third landmarks (Figure 3). For each
landmark, it creates an annotated task (in this case,
1
We use the implementation of hm landmark generation and
reasonable order extraction in the Fast Downward planning system (https://www.fast-downward.org/), configured to only allow
for single-atom (conjunctive) landmarks.

Begin
1
3
2
1
5
4
3
2
1

End
1
3
3
3
5
5
5
5
5

Annotated Task
Make-Clear
Make-Clear
Make-Clear
Make-Clear
Make-Clear
Make-Clear
Make-Clear
Make-Clear
Make-Clear

The curriculum comprises nine steps, labeled from a to i.
Each step is defined by a specific segment of π, delineated
by its beginning and ending indices, along with the name of
an annotated task. The curriculum is structured to initiate
simpler tasks, gradually progressing to more complex ones.
The regressive sequencing of the beginning indices aims at
learning methods with varying preconditions for the same
annotated tasks.

3.2

C URRICU L EARN

C URRICU LAMA’s C URRICU L EARN subroutine learns
HTN methods from curricula, shown in Algorithm 2. The
input to C URRICU L EARN includes a domain description Σ,
an initial states s0 , an execution trace π (which can be a plan
produced by a planner given a goal), a curriculum C, and a
possibly empty set of HTN methods M . For each curriculum step in C, it uses the algorithm L EARN -M ETHOD2 to
perform the analysis on the subtrace π[b, e] and learns some
new methods for τ . It also keeps a set of indexed method instances X to identify and reuse previously learned methods
as subroutines in a new method that is being synthesized.
Specifically, each method is indexed by the beginning index
of the corresponding subtrace b, and the ending index of the
corresponding subtrace e.
Algorithm 2 A high-level description of C URRICU L EARN.
Input: classical domain description Σ, initial state s0 , solution trace π, curriculum C, and a possibly empty set of HTN
methods M
Output: an updated set of HTN methods
1: initialize X ← ∅
⃗ be the state trajectory generated from γ(s0 , π)
2: let S
3: for (b, e, τ ) ∈ C do
⃗ τ, X, b, e)
4:
M ′ ← L EARN -M ETHOD(π, S,
′
5:
M ←M ∪M
6:
for m ∈ M ′ do
7:
X ← X ∪ {(m, b, e)}
8: return M
C URRICU LAMA takes as input a planning problem and
outputs a set of learned HTN methods. It does this by using
2
L EARN -M ETHOD performs hierarchical goal regression over
a plan trace. It is the same procedure that HTN-M AKER uses as a
subroutine (Hogg, Muñoz-Avila, and Kuter 2016, Algorithm 3) to
learn preconditions and subtasks of HTN methods.

C URRICU G EN to generate curricula from landmarks, and
C URRICU L EARN to acquire HTN methods from these curricula. This obviates HTN-M AKER’s need for manual annotation of tasks and corresponding plan subtraces.

4

Theoretical Analysis

We prove that the methods learned by C URRICU LAMA
from a classical planning problem can be applied to solve
the equivalent hierarchical problem. First, we need to go
through the process of C URRICU G EN given a classical planning problem and define the hierarchical planning problem.
Given a classical planning problem P = (Σ, s0 , g) as a
training example, C URRICU G EN produces a solution trace
π and a curriculum C. Given π, C, and a possibly empty
set of HTN methods M , C URRICU L EARN will add newly
learned methods to M . Let τ be an annotated task that has
g as its goals. Then Ph = ((Σ, M ), s0 , ⟨τ ⟩) is the hierarchical planning problem (see Definition 3) equivalent to the
classical planning problem P .
Definition 3. A hierarchical planning problem Ph is a triple
(Σh , s0 , ⟨τ ⟩) where Σh is the hierarchical planning domain
description, s0 is the initial state and ⟨τ ⟩ is the task list.
A hierarchical planning domain description Σh is a tuple
(Σ, M ), where Σ is the classical planning domain description and M is the set of HTN methods.
Now we can show how the methods learned by C URRICU LAMA can be used to solve the hierarchical problem, which
is equivalent to the classical problem from which the methods were learned.
Proposition 1. Given P = (Σ, s0 , g), π, τ , M, and Ph =
((Σ, M ), s0 , ⟨τ ⟩), π is a solution to Ph as a result of hierarchically decomposing g using the methods in M .
Proof Sketch If π is empty or g is satisfied in s0 , then
C URRICU L EARN will learn a trivial method for τ that has
empty subtasks, which is sufficient to solve the problem.
Otherwise, since g has to be the final landmark in the
landmark graph of P , the final curriculum step in C is
(1, len(π), τ ). Therefore, C URRICU L EARN will learn at
least one method from curriculum step (1, len(π), τ ). This
method must be applicable to s0 in Ph because its preconditions were computed by regressing g through the actions
of π (Hogg, Muñoz-Avila, and Kuter 2016, the L EARN M ETHOD precedure), which is applicable to s0 . Furthermore, the goal regression procedure guarantees that whenever the preconditions of a method are satisfied there must
be some way to reduce the subtasks of that method using
other methods learned from π, because the subtasks of that
method were chosen from the indexed instances of other
methods. Eventually, g in Ph will be hierarchically decomposed into the action sequence π. □
Therefore, C URRICU LAMA is sound for the original
problem for which it learned methods. That is, methods
learned by C URRICU LAMA from a classical planning problem P will solve the equivalent hierarchical problem Ph .
However, we also want to know how rapidly it can learn a
complete set of methods from the training problems. In the

next section, we will empirically evaluate C URRICU LAMA
to show that it has a comparable convergence rate in learning
a complete set of methods to HTN-M AKER.

5

Empirical Study

We have evaluated C URRICU LAMA (and compared it to
HTN-M AKER) experimentally in five IPC (International
Planning Competition) domains: Logistics, Blocks World,
Rover, Satellite, and Zeno Travel. These domains are used
for evaluation in the original papers on HTN-Maker. Due
to space limitations, we present results for the Blocks World
and Logistics; results are similar across domains and can be
seen in Appendix B and C. We assess the efficiency of C UR RICU LAMA in learning Hierarchical Task Network methods and the effectiveness in solving hierarchical planning
problems using the learned methods.
Our evaluation considered how well the methods learned
from an incremental set of training problems can solve a set
of static testing problems. A single trial for a domain used
PDDL-Generators (Seipp, Torralba, and Hoffmann 2022) to
generate 150 random training problems and 50 testing problems from the same distribution of parameters. Starting with
an empty set of methods M , the procedure iterated through
the training problems (1, 2, .., 150), augmented M using either C URRICU LAMA or HTN-M AKER, and used HTNM AKER’s version of the SHOP planner (Nau et al. 1999) to
solve the 50 test problems with the current set M . We repeated five trials in each of the five domains and reported
on the following metrics: (1) convergence, (2) average plan
length, (3) average planning time, (4) method generation, (5)
running time in learning. All experiments are run on AMD
EPYC 7763 (2.45 GHz).
Figure 4 shows that C URRICU LAMA’s method learning exhibits a similar convergence rate and results in plan
lengths and planning time comparable to HTN-M AKER, all
while achieving a significant advantage: it completely eliminates the need for expert-provided annotated tasks.
C URRICU LAMA’s planning mechanism may cause it to
learn extraneous methods in some domains (e.g., the Logistics, Satellite and Rover domain). While it’s possible
that this may be an indication of overfitting, we believe
this is more likely a result of partial orders in the landmark graph. The landmark generation algorithms used by
C URRICU LAMA (Algorithm 1, lines 2 and 3) return only a
partial ordering among landmarks given the additional reasonable orders. All reasonable orderings are not determined
because determining whether a reasonable order exists between two given landmarks is a PSPACE-complete problem
(Hoffmann, Porteous, and Sebastia 2004). Then, C URRICU LAMA enforces a total ordering to formulate a sequence of
subgoals, which is not necessarily the optimal strategy (see
Appendix D for an example). This often results in C URRIC U LAMA’s derivation of additional methods from extended
plan traces, as those methods cover more potential (and suboptimal) paths to the goal. Improving C URRICU LAMA’s
strategy for ordering landmarks by incorporating more sophisticated heuristics could help reduce the creation of these
redundant methods and is a topic for future work.

(1) Blocks World domain

(2) Logistics domain

Figure 4: Experimental results in (1) the Blocks World domain and (2) the Logistics domain. From left to right, the subfigure’s y-axis shows (a) the fraction of problems that the planner could successfully solve using the methods that each learning
algorithm learned; (b) the average length of the plans that the planner produced using the learned methods; (c) the average
planning time over the 50 test problems; and (d) the total number of methods learned. In each of the subfigures, the x-axis
shows the number of training problems (0-150) from which the methods were learned. The blue line displays the results for
C URRICU LAMA and the orange dashed line displays the results for HTN-M AKER. The shaded areas indicate the variance in
the number of methods learned across five trials.
While C URRICU LAMA may learn slightly more methods
in some domains due to suboptimal landmark orderings, this
does not appear to have a detrimental impact on planning
success rates or plan lengths. Notably, in domains where
C URRICU LAMA successfully captures all required landmark orderings, it learns fewer methods than HTN-M AKER,
which results in relatively shorter planning time.
It’s also worth highlighting that C URRICU LAMA’s additional computational time (Figure 5), averaging between 0.2
to 0.8 seconds per problem, is negligible when compared to
the overall planning time or the time required from a domain
expert. Thus, C URRICU LAMA is an efficient and promising alternative to acquiring planning methods.

5.1

Future Work

The number of methods and planning time keep increasing without convergence for both algorithms in the Blocks
World, Logistics and Rover domain. We believe that given
enough training problems, they will eventually converge. To
verify that, we will expand the training set in our future experiments.
We are also interested in an empirical study that compares
manually annotated task and automatically annotated tasks
when directly applied to HTN-M AKER without any curric-

ula. This will give an idea of the quality of the tasks generated by C URRICU G EN.
Last but not least, we will theoretically and empirically
analyse C URRICU LAMA’s time complexity as some measure of task domain problem or solution complexity increases.

6

Related work

Several researchers have investigated ways to learn structural knowledge, including HTNs, though they did not use
curricula generated from landmarks to guide learning.
The algorithm by Lotinac and Jonsson (2016) uses invariant analysis to construct an HTN from the PDDL description of a planning domain and a single representative instance. Learn-HTN (Zhuo et al. 2009) learns HTNmethod preconditions and action preconditions and effects
under partial observability. It receives task decomposition
trees whose leaves are all primitive actions. It solves constraints using MAX-SAT among subtask-pairs in a task decomposition tree to learn action models and method preconditions. Similar to Learn-HTN, HTNLearn (Zhuo, MunozAvila, and Yang 2014) learns HTN methods and action models from partially observed plan traces annotated with poten-

Figure 5: Running time needed to learn methods. The bars
represent the average time that each learning algorithm spent
on different parts of the learning process. Green represents
the time to obtain landmarks (Alg 1, Line 2 and 3), blue
indicates the time to obtain the plan (Alg 1, Line 8 to 16) ,
and orange shows the time to learn methods.
tially empty partial decomposition trees that capture tasksubtask decompositions.
The HTN Learning System (Yang, Pan, and Pan 2007)
uses partitioning to learn HTN methods. Other algorithms
learn method preconditions using the hierarchical relationships between tasks, the action models, a complete description of the intermediate states using case-based reasoning
(Xu and Muñoz-Avila 2005) and version-space learning (Ilghami et al. 2005). The algorithm by Li, Kambhampati, and
Yoon (2009) uses techniques similar to probabilistic contextfree grammar learning and learns probabilistic HTNs. It can
learn recursive methods on repeated structures.
Word2HTN (Gopalakrishnan, Munoz-Avila, and Kuter
2016) combines semantic text analysis techniques and subgoal learning to create HTNs. Plan traces are viewed as
sentences where a plan trace consists of actions with their
grounded preconditions and effects. Each word in the sentence is an atom or an action in the plan trace. This work
uses Word2Vec to convert each word into a vector representation and applies agglomerative hierarchical partitioning on the learned vectors to learn methods with binarysubtask decompositions. As an extension to their approach,
(Fine-Morris et al. 2020) approximates landmarks using solution traces and learns methods with symbolic and numeric
preconditions that initially decompose problems using two
or more landmarks, and then finish the decomposing using
(primitive task, complex task) right-recursion.
CC-HTN (Hayes and Scassellati 2016) and Circuit-HTN
(Chen et al. 2021) translate execution traces into multi-trace
graphical representations where primitive tasks comprise
vertices and edges indicate sequential tasks. They apply
bottom-up consolidation techniques to group simple tasks
into progressively larger ones. Circuit-HTN treats the graph
as a circuit of resistors, using techniques from the reduction
of parallel and in-series resistors to discover new decompositions. CC-HTN similarly uses clique- and chain-detection
for structure-learning and also learns the method parameters.
Hérail and Bit-Monnot (2023) iteratively learns HTNs
using bottom-up pattern-recognition and compression tech-

niques on common sequences of subtasks in traces, which
get replaced with a task symbol. Segura-Muros, Pérez, and
Fernández-Olivares (2017) learn HTNs using process and
data mining by converting execution traces into event-logs
and extracting the preconditions and effects for each task
using a fuzzy rule-based learning algorithm.
HPNL (Langley 2022) is a system that learns new methods for Hierarchical Problem Networks (Shrobe 2021) by
analyzing sample hierarchical plans, using violated constraints to identify state conditions, and ordering conflicts
to determine goal conditions.
The hierarchical plan recognition algorithm by
Geib (2009) uses Combinatory Categorial Grammars
(CCGs) as part of the ELEXIR framework. It requires a
hand-authored CCG representing structure of plans done by
agents. LexLearn (Geib and Kantharaju 2018) learns CCGs
by enumerating CCG categories for a set of plan traces
from templates. LexGreedy (Kantharaju 2021) employs a
greedy approach to improve the scalability of CCG learning.
LexTGreedy (Kantharaju 2021) learns CCGs in domains with
type trees as an extension to LexGreedy .
Teleoreactive Logic Programs (TLPs) are a framework for
encoding knowledge using ideas from logic programming,
reactive control, and HTNs. This work includes ways to
learn recursive TLPs from problem solution traces (Choi
and Langley 2005), a learning method that acquires recursive forms of TLP structures from traces of successful problem solving (Langley et al. 2006), and an incremental learning algorithm for TLPs based on explanation-based learning
(Nejati, Langley, and Konik 2006).

7

Conclusion

C URRICU LAMA generates curricula from landmarks and
uses them to acquire HTN methods according to these curricula. We have proved that the methods that C URRICU LAMA learns from classical planning problems enable an
HTN planner to solve equivalent HTN planning problems.
In our experiments C URRICU LAMA learned comparably
good methods to those learned by HTN-M AKER for the
same problems, with no requirement for a human to provide
methods, curricula, or annotations of tasks. The idea that
landmarks are useful for structural knowledge learning, and
that curricula can be constructed from those landmarks, may
apply to other structural knowledge learning techniques.

Acknowledgements
The authors thank the reviewers, whose comments helped to
improve the paper. This work has been supported for UMD
in part by ONR grant N000142012257 and AFRL contract
FA8750-23-C-0515. MR and MFM thank ONR and NRL
for funding this research. The views expressed are those of
the authors and do not reflect the official policy or position
of the funders.

References
[Bengio et al. 2009] Bengio, Y.; Louradour, J.; Collobert, R.;
and Weston, J. 2009. Curriculum learning. In ICML, 41–48.
[Chen et al. 2021] Chen, K.; Srikanth, N. S.; Kent, D.;
Ravichandar, H.; and Chernova, S. 2021. Learning Hierarchical Task Networks with Preferences from Unannotated
Demonstrations. In CoRL, 1572–1581.
[Choi and Langley 2005] Choi, D., and Langley, P. 2005.
Learning teleoreactive logic programs from problem solving. In ILP, 51–68.
[Fine-Morris et al. 2020] Fine-Morris, M.; Auslander, B.;
Floyd, M. W.; Pennisi, G.; Muñoz-Avila, H.; and Gupta,
S. K. M. 2020. Learning hierarchical task networks with
landmarks and numeric fluents by combining symbolic and
numeric regression. In ACS.
[Geib and Kantharaju 2018] Geib, C., and Kantharaju, P.
2018. Learning combinatory categorial grammars for plan
recognition. In AAAI, 3007–3014.
[Geib 2009] Geib, C. W. 2009. Delaying commitment in
plan recognition using combinatory categorial grammars. In
IJCAI, 1702–1707.
[Ghallab, Nau, and Traverso 2016] Ghallab, M.; Nau, D.;
and Traverso, P. 2016. Automated planning and acting.
Cambridge University Press.
[Gopalakrishnan, Munoz-Avila, and Kuter 2016]
Gopalakrishnan, S.; Munoz-Avila, H.; and Kuter, U.
2016. Word2HTN: Learning task hierarchies using statistical semantics and goal reasoning. In IJCAI Workshop on
Goal Reasoning.
[Hayes and Scassellati 2016] Hayes, B., and Scassellati, B.
2016. Autonomously constructing hierarchical task networks for planning and human-robot collaboration. In ICRA,
5469–5476.
[Hoffmann, Porteous, and Sebastia 2004] Hoffmann, J.; Porteous, J.; and Sebastia, L. 2004. Ordered landmarks in planning. JAIR 22:215–278.
[Hogg, Muñoz Avila, and Kuter 2008] Hogg, C.; Muñoz
Avila, H.; and Kuter, U. 2008. HTN-MAKER: Learning
HTNs with minimal additional knowledge engineering required. In AAAI, 950–956.
[Hogg, Muñoz-Avila, and Kuter 2016] Hogg, C.; MuñozAvila, H.; and Kuter, U. 2016. Learning hierarchical
task models from input traces. Computational Intelligence
32(1):3–48.
[Hérail and Bit-Monnot 2023] Hérail, P., and Bit-Monnot,
A. 2023. Leveraging Demonstrations for Learning the
Structure and Parameters of Hierarchical Task Networks. In
FLAIRS, volume 36.
[Ilghami et al. 2005] Ilghami, O.; Munoz-Avila, H.; Nau,
D. S.; and Aha, D. W. 2005. Learning approximate preconditions for methods in hierarchical plans. In ICML, 337–
344.
[Kantharaju 2021] Kantharaju, P. 2021. Learning Decomposition Models for Hierarchical Planning and Plan Recognition. Ph.D. Dissertation, Drexel University, Philadelphia,
Pennsylvania, USA.

[Keyder, Richter, and Helmert 2010] Keyder, E.; Richter, S.;
and Helmert, M. 2010. Sound and complete landmarks for
and/or graphs. In ECAI, 335–340.
[Langley et al. 2006] Langley, P.; Choi, D.; Olsson, R.; and
Schmid, U. 2006. Learning recursive control programs from
problem solving. Journal of Machine Learning Research
7(3).
[Langley 2022] Langley, P. 2022. Learning hierarchical
problem networks for knowledge-based planning. In ILP.
[Li, Kambhampati, and Yoon 2009] Li, N.; Kambhampati,
S.; and Yoon, S. 2009. Learning probabilistic hierarchical task networks to capture user preferences. In IJCAI,
1754–1759.
[Lotinac and Jonsson 2016] Lotinac, D., and Jonsson, A.
2016. Constructing hierarchical task models using invariance analysis. In ECAI. 1274–1282.
[Nau et al. 1999] Nau, D.; Cao, Y.; Lotem, A.; and MunozAvila, H. 1999. Shop: Simple hierarchical ordered planner.
In IJCAI, 968–973.
[Nejati, Langley, and Konik 2006] Nejati, N.; Langley, P.;
and Konik, T. 2006. Learning hierarchical task networks
by observation. In ICML, 665–672.
[Richter and Westphal 2010] Richter, S., and Westphal, M.
2010. The LAMA planner: Guiding cost-based anytime
planning with landmarks. JAIR 39:127–177.
[Segura-Muros, Pérez, and Fernández-Olivares 2017]
Segura-Muros, J. A.; Pérez, R.; and Fernández-Olivares, J.
2017. Learning HTN domains using process mining and
data mining techniques. In ICAPS Workshop on Generalized
Planning.
[Seipp, Torralba, and Hoffmann 2022] Seipp, J.; Torralba,
Á.; and Hoffmann, J. 2022. PDDL generators. https:
//doi.org/10.5281/zenodo.6382173.
[Shrobe 2021] Shrobe, H. E. 2021. Hierarchical problem
networks for knowledge-based planning. In ACS.
[Xu and Muñoz-Avila 2005] Xu, K., and Muñoz-Avila, H.
2005. A domain-independent system for case-based task decomposition without domain theories. In AAAI, 234–240.
[Yang, Pan, and Pan 2007] Yang, Q.; Pan, R.; and Pan, S. J.
2007. Learning recursive htn-method structures for planning. In ICAPS Workshop on AI Planning and Learning.
[Zhuo et al. 2009] Zhuo, H. H.; Hu, D. H.; Hogg, C.; Yang,
Q.; and Munoz-Avila, H. 2009. Learning HTN method
preconditions and action models from partial observations.
In IJCAI, 1804–1809.
[Zhuo, Munoz-Avila, and Yang 2014] Zhuo, H. H.; MunozAvila, H.; and Yang, Q. 2014. Learning hierarchical task
network domains from partially observed plan traces. Artificial Intelligence 212:134–157.

Appendix
A

Landmark Orderings

A landmark graph comes with orderings among landmarks.
For a plan of length n, a landmark lk for 0 ≤ k ≤ n occurs
from the initial state if k = 0 and action ak otherwise; lk′ denotes the first occurrence. There are four types of orderings
among landmark li and lj for 0 ≤ i < j ≤ n (Richter and
Westphal 2010):
• A natural ordering li →n lj for i < j, indicates that li
occurs at some point before lj .
• A necessary ordering li →nec lj for i = j − 1 indicates
that li occurs one step before one of the times lj occurs.
A necessary ordering is a natural ordering.
• A greedy-necessary li →gn lj′ for i = j − 1 indicates
that li occurs one step before the first time lj′ occurs. A
greedy-necessary ordering is a necessary ordering.
• A reasonable ordering li′ →r lj for h < i < j indicates
that lj reoccurs some point after the first time li′ occurs;
i.e., lj previously occurred at some time h and became
false at h + 1. This ordering may save effort in solving
the problem, thus it is ”reasonable”.

B

Detailed Experimental Methodology

We tested C URRICU LAMA against HTN-M AKER in the
following five domains:
• The Blocks World encompasses scenarios where a number of blocks are arranged on a table, potentially stacked
upon each other, with a robotic hand tasked with reorganizing them. Our study’s focus in this domain is on the
reorganization of 5 blocks.
• In the Logistics domain, the primary task involves package delivery within and between cities, utilizing trucks
and airplanes. A typical scenario in our study involves
the delivery of one package across 3 cities, each having 2
specific locations.
• The Rover domain involves navigation through waypoints
and sample collection tasks of objectives on a planetary
surface. We study problems that have at most 2 rovers, 5
waypoints, and 6 objectives.
• In the Satellite domain, the objective is to collect various
images using satellites equipped with different observation instruments. We study problems that have at most 4
satellites, 3 instruments, 8 instrument modes, and 6 targets.
• Zeno Travel involves transportation of passengers between cities using aircraft with varying fuel levels, which
are represented numerically using predicate logic. We
study problems that have at most 6 cities, 5 aircraft, and 5
passengers.
We repeated five trials in each of the five domains and reported on the following metrics:

• Convergence: We measured the convergence rate of the
proportion of test problems the planner could successfully
solve with the methods learned by each HTN learner. If
the methods learned from only a few examples are sufficient to solve most of the testing problems, we say that the
set of methods rapidly converges to one that is complete.
• Average Plan Length: We measured the average length of
the plans for the successfully solved test problems, which
informs us about the efficiency and complexity of the solutions generated by the learning algorithms.
• Average Planning time: We measured the average amount
of time that the planner needed to solve the test problems
using the learned methods.
• Method Generation: We recorded the cumulative number
of methods generated by each of the HTN learners as they
saw more and more training examples.
• Running Time: We compared the running time of the HTN
learners at different stages of the learning process.

C

More Experiments

On the next two pages are figures showing the experimental results for the five domains in our experiments: Blocks
World, Logistics, Satellite, Rover, and Zeno Travel. Figure
6 shows the convergence analysis, Figure 7 shows the average plan lengths, Figure 8 shows the time to solve planning
problems using the learned methods, Figure 9 shows the running time needed to learn methods, and Figure 10 shows the
number of methods learned.

D

Landmarks May Produce Suboptimal
Subgoal Ordering

C URRICU LAMA’s planning mechanism may cause it to
learn extraneous methods in some domains. For illustrative
purposes, consider delivering a package p0 from location l20 to location l0-0 in the Logistics domain. The airplane a0
is initially at location l1-0. The most efficient strategy after
flying the airplane a0 from l1-0 to l2-0 (according to the first
landmark (airplane-at a0 l2-0)) would be to load the
package into the airplane followed by a direct flight to l00. Nonetheless, as depicted in Figure 11, C URRICU LAMA
may adopt a sequence where the airplane first relocates to
l0-0 without the package, resulting in a suboptimal path and
thus an increase in the number of methods learned.

Figure 6: Convergence analysis. The y-axis shows the fraction of problems that the planner could successfully solve using the
methods that each learning algorithm learned, and the x-axis shows the number of training problems from which the methods
were learned. The shaded regions show the variance in problems solved across five separate trials.

Figure 7: Average plan lengths. The y-axis shows the average length of the plans that the planner produced using the learned
methods, and the x-axis shows the number of training problems from which the methods were learned, ranging from zero to
150 training problems. The shaded regions show the variance in plan length across five separate trials.

Figure 8: Time to solve planning problems using the learned methods. The x-axis gives the number of training problems from
which each learning algorithm learned its methods, and the y-axis gives the average planning time over the 50 test problems.
The shaded regions denote the variance in planning time across five separate trials.

Figure 9: Running time needed to learn methods. The bars represent the average time that each learning algorithm spent on
different parts of the learning process. Green represents the time to obtain landmarks, blue indicates the time to get the plan,
and orange shows the time to learn methods.

Figure 10: Number of methods learned. The y-axis is the total number of methods learned, and the x-axis is the number of
training problems from which they were learned. Both algorithms show increases in the number of methods as they are exposed
to more training problems. The shaded areas indicate the variance in the number of methods learned across five trials.

Figure 11: Landmark graph illustrating potential suboptimal planning in C URRICU LAMA. Landmarks are represented by
circles, and edges indicate ordering: ‘r’ for reasonable, ‘n’ for natural, and ‘gn’ for greedy necessary. A missing reasonable
ordering would prioritize (in-airplane p0 a0) before (airplane-at a0 l0-0) to avoid unnecessary airplane movements (marked by the red dashed arrow).

