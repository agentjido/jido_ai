{
  "data": {
    "architecture": {
      "instruct_type": "mistral",
      "modality": "text->text",
      "tokenizer": "Mistral"
    },
    "created": 1721347200,
    "description": "A 12B parameter model with a 128k token context length built by Mistral in collaboration with NVIDIA.\n\nThe model is multilingual, supporting English, French, German, Spanish, Italian, Portuguese, Chinese, Japanese, Korean, Arabic, and Hindi.\n\nIt supports function calling and is released under the Apache 2.0 license.",
    "endpoints": [
      {
        "context_length": 128000,
        "max_completion_tokens": 128000,
        "max_prompt_tokens": null,
        "name": "Chutes | mistralai/mistral-nemo:free",
        "pricing": {
          "completion": "0",
          "image": "0",
          "prompt": "0",
          "request": "0"
        },
        "provider_name": "Chutes",
        "quantization": null,
        "supported_parameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "top_k",
          "min_p",
          "repetition_penalty",
          "logprobs",
          "logit_bias",
          "top_logprobs"
        ]
      }
    ],
    "id": "mistralai/mistral-nemo:free",
    "name": "Mistral: Mistral Nemo (free)"
  }
}