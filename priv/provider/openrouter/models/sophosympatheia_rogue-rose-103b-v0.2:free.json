{
  "data": {
    "architecture": {
      "instruct_type": "vicuna",
      "modality": "text->text",
      "tokenizer": "Llama2"
    },
    "created": 1737195189,
    "description": "Rogue Rose demonstrates strong capabilities in roleplaying and storytelling applications, potentially surpassing other models in the 103-120B parameter range. While it occasionally exhibits inconsistencies with scene logic, the overall interaction quality represents an advancement in natural language processing for creative applications.\n\nIt is a 120-layer frankenmerge model combining two custom 70B architectures from November 2023, derived from the [xwin-stellarbright-erp-70b-v2](https://huggingface.co/sophosympatheia/xwin-stellarbright-erp-70b-v2) base.\n",
    "endpoints": [
      {
        "context_length": 4096,
        "max_completion_tokens": null,
        "max_prompt_tokens": null,
        "name": "Nineteen | sophosympatheia/rogue-rose-103b-v0.2:free",
        "pricing": {
          "completion": "0",
          "image": "0",
          "prompt": "0",
          "request": "0"
        },
        "provider_name": "Nineteen",
        "quantization": "int4",
        "supported_parameters": [
          "max_tokens",
          "temperature",
          "top_p"
        ]
      }
    ],
    "id": "sophosympatheia/rogue-rose-103b-v0.2:free",
    "name": "Rogue Rose 103B v0.2 (free)"
  }
}