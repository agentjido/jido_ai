{
  "data": {
    "architecture": {
      "instruct_type": "llama3",
      "modality": "text->text",
      "tokenizer": "Llama3"
    },
    "created": 1728950400,
    "description": "NVIDIA's Llama 3.1 Nemotron 70B is a language model designed for generating precise and useful responses. Leveraging [Llama 3.1 70B](/models/meta-llama/llama-3.1-70b-instruct) architecture and Reinforcement Learning from Human Feedback (RLHF), it excels in automatic alignment benchmarks. This model is tailored for applications requiring high accuracy in helpfulness and response generation, suitable for diverse user queries across multiple domains.\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
    "endpoints": [
      {
        "context_length": 131000,
        "max_completion_tokens": 131000,
        "max_prompt_tokens": null,
        "name": "Lambda | nvidia/llama-3.1-nemotron-70b-instruct",
        "pricing": {
          "completion": "0.0000003",
          "image": "0",
          "prompt": "0.00000012",
          "request": "0"
        },
        "provider_name": "Lambda",
        "quantization": "fp8",
        "supported_parameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "seed",
          "logit_bias",
          "logprobs",
          "top_logprobs",
          "response_format"
        ]
      },
      {
        "context_length": 131072,
        "max_completion_tokens": 8192,
        "max_prompt_tokens": null,
        "name": "DeepInfra | nvidia/llama-3.1-nemotron-70b-instruct",
        "pricing": {
          "completion": "0.0000003",
          "image": "0",
          "prompt": "0.00000012",
          "request": "0"
        },
        "provider_name": "DeepInfra",
        "quantization": "fp8",
        "supported_parameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "response_format",
          "top_k",
          "seed",
          "min_p"
        ]
      },
      {
        "context_length": 32768,
        "max_completion_tokens": null,
        "max_prompt_tokens": null,
        "name": "Together | nvidia/llama-3.1-nemotron-70b-instruct",
        "pricing": {
          "completion": "0.00000088",
          "image": "0",
          "prompt": "0.00000088",
          "request": "0"
        },
        "provider_name": "Together",
        "quantization": null,
        "supported_parameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "top_k",
          "repetition_penalty",
          "logit_bias",
          "min_p",
          "response_format"
        ]
      },
      {
        "context_length": 32000,
        "max_completion_tokens": null,
        "max_prompt_tokens": null,
        "name": "Infermatic | nvidia/llama-3.1-nemotron-70b-instruct",
        "pricing": {
          "completion": "0.000001",
          "image": "0",
          "prompt": "0.000001",
          "request": "0"
        },
        "provider_name": "Infermatic",
        "quantization": "unknown",
        "supported_parameters": [
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "repetition_penalty",
          "logit_bias",
          "top_k",
          "min_p",
          "seed"
        ]
      }
    ],
    "id": "nvidia/llama-3.1-nemotron-70b-instruct",
    "name": "NVIDIA: Llama 3.1 Nemotron 70B Instruct"
  }
}