{
  "id": "meta-llama/llama-3.2-90b-vision-instruct",
  "name": "Meta: Llama 3.2 90B Vision Instruct",
  "description": "The Llama 90B Vision model is a top-tier, 90-billion-parameter multimodal model designed for the most challenging visual reasoning and language tasks. It offers unparalleled accuracy in image captioning, visual question answering, and advanced image-text comprehension. Pre-trained on vast multimodal datasets and fine-tuned with human feedback, the Llama 90B Vision is engineered to handle the most demanding image-based AI tasks.\n\nThis model is perfect for industries requiring cutting-edge multimodal AI capabilities, particularly those dealing with complex, real-time visual and textual analysis.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
  "capabilities": {
    "code": false,
    "image": true,
    "chat": true,
    "embedding": false,
    "vision": true,
    "multimodal": true,
    "audio": false
  },
  "tier": {
    "value": "basic",
    "description": "Entry-level model"
  },
  "architecture": {
    "modality": "text+image->text",
    "tokenizer": "Llama3",
    "instruct_type": "llama3"
  },
  "created": 1727222400,
  "endpoints": []
}