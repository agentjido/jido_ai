{
  "data": {
    "architecture": {
      "instruct_type": null,
      "modality": "text->text",
      "tokenizer": "Mistral"
    },
    "created": 1704844800,
    "description": "With 22 billion parameters, Mistral Small v24.09 offers a convenient mid-point between (Mistral NeMo 12B)[/mistralai/mistral-nemo] and (Mistral Large 2)[/mistralai/mistral-large], providing a cost-effective solution that can be deployed across various platforms and environments. It has better reasoning, exhibits more capabilities, can produce and reason about code, and is multiligual, supporting English, French, German, Italian, and Spanish.",
    "endpoints": [
      {
        "context_length": 32000,
        "max_completion_tokens": null,
        "max_prompt_tokens": null,
        "name": "Mistral | mistralai/mistral-small",
        "pricing": {
          "completion": "0.0000006",
          "image": "0",
          "prompt": "0.0000002",
          "request": "0"
        },
        "provider_name": "Mistral",
        "quantization": "unknown",
        "supported_parameters": [
          "tools",
          "tool_choice",
          "max_tokens",
          "temperature",
          "top_p",
          "stop",
          "frequency_penalty",
          "presence_penalty",
          "response_format",
          "structured_outputs",
          "seed"
        ]
      }
    ],
    "id": "mistralai/mistral-small",
    "name": "Mistral Small"
  }
}